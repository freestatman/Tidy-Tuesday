---
title: "TidyTuesdayGDPR"
author: "Andrew Couch"
date: "4/21/2020"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
library(tidyverse)
gdpr_violations <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_violations.tsv')
gdpr_text <- readr::read_tsv('https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2020/2020-04-21/gdpr_text.tsv')
```

```{r}
#France, Italy, and Germany have the highest amount of fines
gdpr_violations %>% 
  group_by(name) %>% 
  summarise(total = sum(price)) %>% 
  ungroup() %>% 
  ggplot(aes(x = reorder(name, total), y = total)) + geom_col() + coord_flip()
```


```{r}
#Spain, Germany, and Romana have been fined the most frequently 
gdpr_violations %>% 
  count(name, name) %>%  
  ggplot(aes(x = reorder(name, n), y = n)) + geom_col() + coord_flip()
```

```{r}
gdpr_text %>% 
  select(article, sub_article) %>% 
  distinct()
```

```{r}
#Key to link the violations with text
gdpr_text %>% 
  select(article, article_title, text = gdpr_text) %>% 
  distinct()
```



```{r}
#GDPR Violations with the extracted article
gdpr_price <- gdpr_violations %>% 
  select(date, name, price, article_violated) %>% 
  separate_rows(article_violated, sep = "\\|") %>% 
  mutate(article = str_extract(article_violated, "[0-9][0-9]?")) %>% 
  select(-article_violated)
```


```{r}
gdpr_price %>% 
  ggplot(aes(x = name, y = price, color = name)) + geom_boxplot(show.legend = FALSE) + geom_jitter(alpha = .1, show.legend = FALSE) + coord_flip() + scale_y_log10()
```



```{r}
library(tidytext)
#Conversion of n-grams
gdbr_words <- gdpr_text %>% 
  select(article, text = gdpr_text) %>% 
  unnest_tokens("word", "text", token = "words")

gdbr_bigrams <- gdpr_text %>% 
  select(article, text = gdpr_text) %>% 
  unnest_tokens("word", "text", token = "ngrams", n = 2)

gdbr_trigrams <- gdpr_text %>% 
  select(article, text = gdpr_text) %>% 
  unnest_tokens("word", "text", token = "ngrams", n = 3)
```




```{r}
gdbr_words %>% 
  anti_join(stop_words) %>% 
  count(word, sort = TRUE) %>% 
  top_n(n, n = 5) 
```


```{r}
#These articles have the most amount of sentiment positive and negative
gdbr_words %>% 
  inner_join(get_sentiments(lexicon = "bing")) %>% 
  group_by(article) %>% 
  count(sentiment) %>% 
  group_by(sentiment) %>% 
  top_n(n, n = 3)
```




```{r}
gdpr_text %>% select(gdpr_text)
```


```{r}
library(topicmodels)
gdpr_dtm <- gdbr_words %>% 
  count(article, word) %>% 
  anti_join(stop_words) %>% 
  cast_dtm(document = "article", term = "word", value = "n")


gdpr_topic_model <- LDA(gdpr_dtm, k = 5)
```


```{r,fig.height=10,fig.width=10}
#What terms make up a topic?
tidy(gdpr_topic_model, matrix = "beta") %>% 
  group_by(topic) %>% 
  top_n(beta, n = 5) %>% 
  ungroup() %>% 
  mutate(topic = as.factor(topic)) %>% 
  ggplot(aes(x = reorder_within(term, beta, topic), y = beta, fill = topic)) + 
  geom_col() + 
  scale_x_reordered() + 
  coord_flip() + 
  facet_wrap(~topic, scales = "free") + 
  theme(legend.position = "none")
```


```{r,fig.height=10,fig.width=10}
#Where does the topic belong in the GDPR article? 
tidy(gdpr_topic_model, matrix = "gamma") %>% 
  group_by(document) %>% 
  top_n(gamma, n = 1) %>% 
  ungroup() %>% 
  mutate(topic = as.factor(topic)) %>% 
  ggplot(aes(x = document, y = topic, color = topic)) + 
  geom_point() + 
  theme(legend.position = "top") +
  scale_x_discrete(breaks = NULL) + 
  scale_y_discrete(breaks = NULL) + 
  ggtitle("Where does each topic belong in GDPR?")

```


```{r}
#Instead of topic modeling let's do something simpler and faster 
gdpr_tf <- gdbr_words %>% 
  count(article, word) %>% 
  bind_tf_idf(word, article, n) %>% 
  group_by(article) %>% 
  top_n(tf_idf, n =3) %>% 
  ungroup() %>% 
  arrange(article, -tf_idf)
gdpr_tf
```


```{r}
library(tidylo)
gdpr_log <- gdbr_words %>% 
  count(article, word) %>% 
  bind_log_odds(article, word, n) %>% 
  group_by(article) %>% 
  top_n(log_odds, n = 3) %>% 
  ungroup() %>% 
  arrange(article, -log_odds)

gdpr_log
```



```{r}
#What are predictions are different? 
setdiff(gdpr_tf %>% select(article, word),
gdpr_log %>% select(article, word))

```


```{r}

shared_words <- intersect(gdpr_tf %>% select(article, word, article),
gdpr_log %>% select(article, word, article)) 

shared_words
```




```{r}
gdpr_violations %>% 
  unnest_tokens("word", "summary", token = "ngrams", n = 3,drop = TRUE) %>% 
  select(name, word) %>% 
  count(name, word) %>% 
  bind_tf_idf(word, name, n) %>% 
  group_by(name) %>% 
  top_n(tf_idf, n = 3) %>% 
  ungroup() %>% 
  select(name, word, tf_idf) %>% 
  top_n(tf_idf, n = 4) %>% 
  ggplot(aes(x = reorder(word, -tf_idf), y = tf_idf, fill = name)) + geom_col() + theme(legend.position = "top", axis.text.x = element_text(angle = 45, hjust = 1))
```


















